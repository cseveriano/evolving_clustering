{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20191216 -  Evolving Clustering - Data Processing Speed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvkSk8KtuS6G",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing Comparison\n",
        "\n",
        "Comparison between\n",
        "* DenStream\n",
        "* CluStream\n",
        "* microTEDAClus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvftB9thKxyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T23fMyf0LEXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/meminfo | grep 'MemAvailable'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkQj8g5ydYvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/gdrive/My Drive/Evolving_Results/major_review/Final/\"\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM_Ms0hLdhfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!apt-get update\n",
        "!apt-get install r-base\n",
        "!pip install rpy2\n",
        "!apt-get install libmagick++-dev\n",
        "#!apt-get install r-cran-rjava\n",
        "\n",
        "import os       #importing os to set environment variable\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server\"\n",
        "  !java -version       #check java version\n",
        "\n",
        "install_java()\n",
        "\n",
        "!R CMD javareconf\n",
        "\n",
        "#!apt-get install r-cran-rjava\n",
        "#!apt-get install libgdal-dev libproj-dev\n",
        "\n",
        "!R -e 'install.packages(c(\"magick\",  \"animation\", \"stream\", \"rJava\", \"streamMOA\"))'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0WEwf0Zdly1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# enables the %%R magic, not necessary if you've already done this\n",
        "%load_ext rpy2.ipython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M54tdfMGdoeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "dyn.load(\"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so\")\n",
        "library(\"stream\")\n",
        "library(\"streamMOA\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO0Jr9ecdrUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "\n",
        "gaussian_data_generator <- function(dimension, nsamples){\n",
        "  stream <- DSD_Gaussians(k=3, d=dimension)\n",
        "  return (get_points(stream, n = nsamples, class = TRUE))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYC3vRj7uvEX",
        "colab_type": "text"
      },
      "source": [
        "### Import Python Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn4ugxrPXuEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Evolving Clustering version with first norm adjust factor\n",
        "!pip install -U git+https://github.com/cseveriano/evolving_clustering@6dfd88385b38115c153e43d57a187653123e6399"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUB5kXTgFB9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "importlib.reload(EvolvingClustering)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EzwemLbufiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U git+https://github.com/cseveriano/evolving_clustering\n",
        "!pip install numba\n",
        "!pip install python-igraph\n",
        "!pip install -U scikit-multiflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_lx0To52EHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn import datasets\n",
        "\n",
        "import time\n",
        "\n",
        "from benchmarks.denstream.DenStream import DenStream\n",
        "from benchmarks.clustream.CluStream import CluStream\n",
        "from evolving import EvolvingClustering\n",
        "from evolving import EvolvingClustering2\n",
        "from evolving import Benchmarks\n",
        "from google.colab import files\n",
        "\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "r = robjects.r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKb_Bt_jvajw",
        "colab_type": "text"
      },
      "source": [
        "### Load Stream Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltx4lK3w8Z-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nsamples = 4000\n",
        "window_size = 100\n",
        "train_size = 100\n",
        "dims = 10 # [2, 3, 5, 10, 20, 30, 50]\n",
        "trials = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z260n74heR9a",
        "colab_type": "text"
      },
      "source": [
        "### StreamMOA Dataset Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kte5zJ62eWeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stream_df = pandas2ri.ri2py_dataframe(r.gaussian_data_generator(dims, nsamples))\n",
        "X_columns = stream_df.columns[:-1]\n",
        "X = stream_df[X_columns].values\n",
        "y = stream_df['class'].values\n",
        "X = preprocessing.scale(X)\n",
        "minmaxscaler = preprocessing.MinMaxScaler()\n",
        "minmaxscaler.fit(X)\n",
        "X = minmaxscaler.transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WiIZQyTY5tO",
        "colab_type": "text"
      },
      "source": [
        "## Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me9zecVnD6uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuning_size = train_size\n",
        "\n",
        "def fit_predict(method, data, labels, window_size, metric):\n",
        "        train_data = data[:window_size]\n",
        "        test_data = data[window_size:(window_size*2)]\n",
        "\n",
        "        method.fit(train_data)\n",
        "        y_hat = method.predict(test_data)\n",
        "        y = labels[window_size:(window_size*2)]\n",
        "\n",
        "        return metric(y, y_hat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAUKFkszFt26",
        "colab_type": "text"
      },
      "source": [
        "### Evolving Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfMdCNBEDMD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clustering_objective(params):\n",
        "  print(params)\n",
        "\n",
        "  try:\n",
        "    evol_model = EvolvingClustering.EvolvingClustering(variance_limit=params['variance_limit'], debug=False)\n",
        "    error = fit_predict(evol_model, X, y, tuning_size, adjusted_rand_score)\n",
        "  except Exception:\n",
        "    traceback.print_exc()\n",
        "    error = -1\n",
        "\n",
        "  return {'loss': -error, 'status': STATUS_OK}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhb31Kr3ExyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from hyperopt import space_eval\n",
        "import itertools\n",
        "import traceback\n",
        "\n",
        "###### OPTIMIZATION ROUTINES ###########\n",
        "l1 = list(np.arange(0.1,1,0.1))\n",
        "l2 = list(np.arange(0.01,0.1,0.01))\n",
        "l3 = list(np.arange(0.001,0.01,0.001))\n",
        "l4 = list(np.arange(0.0001,0.001,0.0002))\n",
        "l5 = list(np.arange(0.00001,0.0001,0.00002))\n",
        "\n",
        "space = {'variance_limit': hp.choice('variance_limit', list(itertools.chain(l1, l2, l3, l4, l5)))}\n",
        "\n",
        "exp_trials = Trials()\n",
        "best = fmin(clustering_objective, space, algo=tpe.suggest, max_evals=500, trials=exp_trials)\n",
        "print('best: ')\n",
        "print(space_eval(space, best))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjThH3ROZJ6_",
        "colab_type": "text"
      },
      "source": [
        "### DenStream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNQyRadUY8_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lambdas = [0.001, 0.01, 0.1, 0.25, 0.5 , 1]\n",
        "epsilons = [0.01, 0.1, 1, 10, 20]\n",
        "mus = [2, 3, 4, 8, 10, 15, 20]\n",
        "betas = [0.001, 0.01, 0.1, 0.4, 0.5, 0.6, 1, 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxBX-mXGZWs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuning_df = pd.DataFrame(columns=['Lambda', 'Epsilon', 'Mu', 'Beta', 'Error'])\n",
        "\n",
        "for lambd in lambdas:\n",
        "  for epsilon in epsilons:\n",
        "    for mu in mus:\n",
        "      for beta in betas:\n",
        "        print(\"Parameters: lambda=\",lambd, \" eps=\",epsilon, \" mu=\",mu, \" beta=\", beta)\n",
        "        try:\n",
        "          denstream_model = DenStream(lambd=lambd, eps=epsilon, beta=beta, mu=mu)\n",
        "          error = fit_predict(denstream_model, X, y, tuning_size, adjusted_rand_score)\n",
        "          tuning_df = tuning_df.append({'Lambda': lambd, 'Epsilon': epsilon, 'Mu': mu, 'Beta': beta, 'Error': error}, ignore_index=True)\n",
        "        except Exception as e:\n",
        "          print(\"Erro nos parametros: \",e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmoJGEgFmDQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denstream_best_result = tuning_df.sort_values(by=['Error']).loc[tuning_df['Error'] > 0].iloc[-1]\n",
        "denstream_best_lambda = denstream_best_result.Lambda\n",
        "denstream_best_eps = denstream_best_result.Epsilon\n",
        "denstream_best_mu = denstream_best_result.Mu\n",
        "denstream_best_beta = denstream_best_result.Beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3M2nwRdCvQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denstream_best_lambda = 0.1\n",
        "denstream_best_eps = 0.3\n",
        "denstream_best_mu = 3\n",
        "denstream_best_beta = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwmJmPP7wtEZ",
        "colab_type": "text"
      },
      "source": [
        "### CluStream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67cUfTiWw3zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "microclusters = [10, 100, 200, 300]\n",
        "horizons = [10, 100, 500, 1000]\n",
        "ts = [1,2,4,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAB8L6Piwr9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustream_tuning_df = pd.DataFrame(columns=['MC', 'Horizon', 'RadiusFactor', 'Error'])\n",
        "\n",
        "for mc in microclusters:\n",
        "  for h in horizons:\n",
        "    for t in ts:\n",
        "      print(\"Parameters: MC=\",mc, \" Horizon=\",h, \" Radius=\", t)\n",
        "      try:\n",
        "        clustream_model = CluStream(q=mc, m=mc, radius_factor = t, delta=h, k=5, init_number=100)\n",
        "        error = fit_predict(clustream_model, X, y, tuning_size, adjusted_rand_score)\n",
        "        clustream_tuning_df = clustream_tuning_df.append({'MC': mc, 'Horizon': h, 'RadiusFactor': t, 'Error': error}, ignore_index=True)\n",
        "      except:\n",
        "        print(\"Error in parameter configuration\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK1Kj6HEjWR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustream_best_result = clustream_tuning_df.sort_values(by=['Error']).loc[clustream_tuning_df['Error'] > 0].iloc[-1]\n",
        "clustream_best_mc = int(clustream_best_result.MC)\n",
        "clustream_best_horizon = int(clustream_best_result.Horizon)\n",
        "clustream_best_radius = clustream_best_result.RadiusFactor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzrzqMna0yEs",
        "colab_type": "text"
      },
      "source": [
        "## Run Optmized Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmumayfpAwU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error_evolving_df = pd.DataFrame()\n",
        "time_evolving_df = pd.DataFrame()\n",
        "\n",
        "error_denstream_df = pd.DataFrame()\n",
        "time_denstream_df = pd.DataFrame()\n",
        "\n",
        "error_clustream_df = pd.DataFrame()\n",
        "time_clustream_df = pd.DataFrame()\n",
        "\n",
        "for i in np.arange(trials):\n",
        "  print(\"Trial: \",i)\n",
        "\n",
        "  stream_df = pandas2ri.ri2py_dataframe(r.gaussian_data_generator(dims, nsamples))\n",
        "  X_columns = stream_df.columns[:-1]\n",
        "  X = stream_df[X_columns].values\n",
        "  y = stream_df['class'].values\n",
        "  X = preprocessing.scale(X)\n",
        "  minmaxscaler = preprocessing.MinMaxScaler()\n",
        "  minmaxscaler.fit(X)\n",
        "  X = minmaxscaler.transform(X)\n",
        "\n",
        "  print(\"Running DenStream\")\n",
        "  denstream_model = DenStream(lambd=denstream_best_lambda, eps=denstream_best_eps, mu=denstream_best_mu, beta=denstream_best_beta)\n",
        "  denstream_results = Benchmarks.prequential_evaluation(denstream_model, X, y, adjusted_rand_score, train_size, window_size, elapsed_time=True)\n",
        "\n",
        "  print(\"Running Evolving\")\n",
        "  evol_model = EvolvingClustering.EvolvingClustering(variance_limit=0.001, debug=False)\n",
        "  evolving_results = Benchmarks.prequential_evaluation(evol_model, X, y, adjusted_rand_score, train_size, window_size, elapsed_time=True)\n",
        "\n",
        "  print(\"Running CluStream\")\n",
        "  clustream_model = CluStream(q=clustream_best_mc, m=clustream_best_mc, radius_factor = clustream_best_radius, delta=clustream_best_horizon, k=5, init_number=100)\n",
        "  clustream_results = Benchmarks.prequential_evaluation(clustream_model, X, y, adjusted_rand_score, train_size, window_size, elapsed_time=True)\n",
        "\n",
        "  error_evolving_df[\"Trial-\"+str(i)] = evolving_results['error_list']\n",
        "  error_evolving_df.to_csv(path+\"results_procspeed_\"+str(dims)+\"_dim_error_evolving.csv\")\n",
        "  time_evolving_df[\"Trial-\"+str(i)] = evolving_results['elapsed_time_list']\n",
        "  time_evolving_df.to_csv(path+\"results_procspeed_\"+str(dims)+\"_dim_time_evolving.csv\")\n",
        "\n",
        "  error_denstream_df[\"Trial-\"+str(i)] = denstream_results['error_list']\n",
        "  error_denstream_df.to_csv(path+\"results_procspeed_\"+str(dims)+\"_dim_error_denstream.csv\")\n",
        "  time_denstream_df[\"Trial-\"+str(i)] = denstream_results['elapsed_time_list']\n",
        "  time_denstream_df.to_csv(path+\"results_procspeed_\"+str(dims)+\"_dim_time_denstream.csv\")\n",
        "\n",
        "  error_clustream_df[\"Trial-\"+str(i)] = clustream_results['error_list']\n",
        "  error_clustream_df.to_csv(path+\"results_procspeed_\"+str(dims)+\"_dim_error_clustream.csv\")\n",
        "  time_clustream_df[\"Trial-\"+str(i)] = clustream_results['elapsed_time_list']\n",
        "  time_clustream_df.to_csv(path+\"results_procspeed_\"+str(dims)+\"_dim_time_clustream.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1gxKf_SB-fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ramQncAXnqN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"results_procspeed_\"+str(dims)+\"_dim_error_evolving.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss0ZLoQynvcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"results_procspeed_\"+str(dims)+\"_dim_time_evolving.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LyODx4qIfxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"results_procspeed_\"+str(dims)+\"_dim_error_denstream.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Z7NH_6IiJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"results_procspeed_\"+str(dims)+\"_dim_time_denstream.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMRUwdTSI5eK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"results_procspeed_\"+str(dims)+\"_dim_error_clustream.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0oBdzweI-Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"results_procspeed_\"+str(dims)+\"_dim_time_clustream.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccpeJqhnn2Iz",
        "colab_type": "text"
      },
      "source": [
        "### Evolving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o1mSf_kYk5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error_df = pd.DataFrame()\n",
        "time_df = pd.DataFrame()\n",
        "\n",
        "for i in np.arange(trials):\n",
        "  print(\"Trial: \",i)\n",
        "\n",
        "  X, y = datasets.make_blobs(n_samples=nsamples, centers=3, n_features=dims, random_state=0)\n",
        "  X = preprocessing.scale(X)\n",
        "  minmaxscaler = preprocessing.MinMaxScaler()\n",
        "  minmaxscaler.fit(X)\n",
        "  X = minmaxscaler.transform(X)\n",
        "\n",
        "  evol_model = EvolvingClustering.EvolvingClustering(variance_limit=0.001, debug=False)\n",
        "  evolving_results = Benchmarks.prequential_evaluation(evol_model, X, y, adjusted_rand_score, train_size, window_size, elapsed_time=True)\n",
        "\n",
        "  error_df[\"Trial-\"+str(i)] = evolving_results['error_list']\n",
        "  error_df.to_csv(\"results_procspeed_\"+str(dims)+\"_dim_error_evolving.csv\")\n",
        "  time_df[\"Trial-\"+str(i)] = evolving_results['elapsed_time_list']\n",
        "  time_df.to_csv(\"results_procspeed_\"+str(dims)+\"_dim_time_evolving.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zGH1qTvoCn4",
        "colab_type": "text"
      },
      "source": [
        "### DenStream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbohYZr3vd_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error_df = pd.DataFrame()\n",
        "time_df = pd.DataFrame()\n",
        "\n",
        "for i in np.arange(trials):\n",
        "  print(\"Trial: \",i)\n",
        "\n",
        "  X, y = datasets.make_blobs(n_samples=nsamples, centers=3, n_features=dims, random_state=0)\n",
        "  X = preprocessing.scale(X)\n",
        "  minmaxscaler = preprocessing.MinMaxScaler()\n",
        "  minmaxscaler.fit(X)\n",
        "  X = minmaxscaler.transform(X)\n",
        "  \n",
        "  denstream_model = DenStream(lambd=denstream_best_lambda, eps=denstream_best_eps, mu=denstream_best_mu, beta=denstream_best_beta)\n",
        "  denstream_results = Benchmarks.prequential_evaluation(denstream_model, X, y, adjusted_rand_score, train_size, window_size, elapsed_time=True)\n",
        "\n",
        "  error_df[\"Trial-\"+str(i)] = denstream_results['error_list']\n",
        "  error_df.to_csv(\"results_procspeed_\"+str(dims)+\"_dim_error_denstream.csv\")\n",
        "  time_df[\"Trial-\"+str(i)] = denstream_results['elapsed_time_list']\n",
        "  time_df.to_csv(\"results_procspeed_\"+str(dims)+\"_dim_time_denstream.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00gX41reoa2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9OnEe5jodpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_swHUIMZojDD",
        "colab_type": "text"
      },
      "source": [
        "### CluStream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UhB1iZgRik7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error_df = pd.DataFrame()\n",
        "time_df = pd.DataFrame()\n",
        "\n",
        "for i in np.arange(trials):\n",
        "  print(\"Trial: \",i)\n",
        "\n",
        "  X, y = datasets.make_blobs(n_samples=nsamples, centers=3, n_features=dims, random_state=0)\n",
        "  X = preprocessing.scale(X)\n",
        "  minmaxscaler = preprocessing.MinMaxScaler()\n",
        "  minmaxscaler.fit(X)\n",
        "  X = minmaxscaler.transform(X)\n",
        "\n",
        "  clustream_model = CluStream(q=clustream_best_mc, m=clustream_best_mc, radius_factor = clustream_best_radius, delta=clustream_best_horizon, k=5, init_number=100)\n",
        "  clustream_results = Benchmarks.prequential_evaluation(clustream_model, X, y, adjusted_rand_score, train_size, window_size, elapsed_time=True)\n",
        "\n",
        "  error_df[\"Trial-\"+str(i)] = clustream_results['error_list']\n",
        "  error_df.to_csv(\"results_procspeed_\"+str(dims)+\"_dim_error_clustream.csv\")\n",
        "  time_df[\"Trial-\"+str(i)] = clustream_results['elapsed_time_list']\n",
        "  time_df.to_csv(\"results_procspeed_\"+str(dims)+\"_dim_time_clustream.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCT0dOcT_MWy",
        "colab_type": "text"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoM58c5s_Pas",
        "colab_type": "text"
      },
      "source": [
        "### Time per sample vs Timestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBS5PIOl_YcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(14,6))\n",
        "\n",
        "windows = np.arange(train_size+window_size,nsamples+window_size,window_size)\n",
        "plt.plot(windows,denstream_results['elapsed_time_list'],'o-', color='blue',label='DenStream')\n",
        "plt.plot(windows,evolving_results['elapsed_time_list'],'o-', color='orange',label='microTEDAclus')\n",
        "plt.plot(windows,clustream_results['elapsed_time_list'],'o-', color='green',label='CluStream')\n",
        "\n",
        "#labels = ['2', '3', '5', '10', '20', '30', '50']\n",
        "#xticks = [2,3,5,10,20,30,50]\n",
        "\n",
        "#plt.xticks(xticks, labels)\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Time per Sample (ms)')\n",
        "plt.legend()\n",
        "#plt.savefig(\"scalability_plot_mcs.png\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLPIm3FHOSZD",
        "colab_type": "text"
      },
      "source": [
        "### Adj Rand Error vs Timestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6m1QxB2DKDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(14,6))\n",
        "\n",
        "windows = np.arange(train_size+window_size,nsamples+window_size,window_size)\n",
        "plt.plot(windows,denstream_results['error_list'],'o-', color='blue',label='DenStream')\n",
        "plt.plot(windows,evolving_results['error_list'],'o-', color='orange',label='microTEDAclus')\n",
        "plt.plot(windows,clustream_results['error_list'],'o-', color='green',label='CluStream')\n",
        "\n",
        "#labels = ['2', '3', '5', '10', '20', '30', '50']\n",
        "#xticks = [2,3,5,10,20,30,50]\n",
        "\n",
        "#plt.xticks(xticks, labels)\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Adj Rand Index')\n",
        "plt.legend()\n",
        "#plt.savefig(\"scalability_plot_mcs.png\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaWuKSu1OYca",
        "colab_type": "text"
      },
      "source": [
        "## Save results to File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8fhhqKuqmxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment_results = pd.DataFrame({'DenStream_Time': denstream_time_list, 'DenStream_cRand': denstream_error_list, \n",
        "                                   'CluStream_Time': clustream_time_list, 'CluStream_cRand': clustream_error_list,\n",
        "                                   'Evolving_Time': evolving_time_list, 'Evolving_cRand': evolving_error_list})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZz-ovXzr1wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ3jL6TirS5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment_results.to_csv('proc_speed_'+str(dims)+'_dim.csv') \n",
        "files.download('proc_speed_'+str(dims)+'_dim.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}